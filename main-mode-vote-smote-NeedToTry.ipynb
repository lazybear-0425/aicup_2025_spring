{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f900b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE, SelectKBest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a541c5a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7a1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_binary(X_train, y_train, X_test, y_test, group_size=27, n_estimators=100):\n",
    "    clf = GradientBoostingClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    num_class = [(y_train == 0).sum(), (y_train == 1).sum()]\n",
    "    num_class = {i: len(y_train) / num for i, num in enumerate(num_class)}\n",
    "    sample_weight = np.zeros(len(y_train))\n",
    "    for i in range(2):\n",
    "        sample_weight[np.where(y_train == i)] = num_class[i]\n",
    "    \n",
    "    clf.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        \n",
    "    predicted = clf.predict_proba(X_test)\n",
    "    # 取出正類（index 1）的概率\n",
    "    predicted = [predicted[i][1] for i in range(len(predicted))]\n",
    "\n",
    "    y_pred = []\n",
    "    num_groups = len(predicted) // group_size \n",
    "    for i in range(num_groups):\n",
    "        now_group = np.array(predicted[i*group_size: (i+1)*group_size])\n",
    "        pred_label = 0 if (now_group <= 0.5).sum() > (now_group > 0.5).sum() else 1 # 決定他是0還是1\n",
    "        if pred_label == 0: \n",
    "            pos_mask = now_group <= 0.5\n",
    "            y_pred.append(now_group[pos_mask].min())\n",
    "        else: \n",
    "            pos_mask = now_group > 0.5\n",
    "            y_pred.append(now_group[pos_mask].max())            \n",
    "        \n",
    "    y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test_agg, y_pred, average='micro')\n",
    "    print(f'ROC {auc_score:.4f}')\n",
    "    print('==========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca8f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義多類別分類評分函數 (例如 play years、level)\n",
    "def model_multiary(X_train, y_train, X_test, y_test, group_size=27, n_estimators=100, classifier=None):\n",
    "    y_train_binary = np.logical_or(y_train == 0, y_train == 2)\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42, class_weight='balanced', \n",
    "                                     criterion='entropy', oob_score=True)\n",
    "    clf.fit(X_train, y_train_binary)\n",
    "    \n",
    "    y_test_binary = np.logical_or(y_test == 0, y_test == 2).astype(int)\n",
    "    \n",
    "    predicted = clf.predict_proba(X_test)\n",
    "    num_groups = len(predicted) // group_size\n",
    "    y_pred = []\n",
    "    for i in range(num_groups):\n",
    "        # 為了移除Outlier\n",
    "        group_pred = np.array(predicted[i*group_size: (i+1)*group_size])\n",
    "        num_classes = len(np.unique(y_train_binary))\n",
    "        group_label = np.argmax(group_pred, axis=1) # 算出每筆最大類\n",
    "        label = np.bincount(group_label).argmax() # 算出最多投票\n",
    "        pos_mask = group_label == label\n",
    "        group_pred = group_pred[pos_mask, :].tolist()\n",
    "        # 對每個類別計算該組內的總機率\n",
    "        class_sums = [sum([group_pred[k][j] for k in range(len(group_pred))]) for j in range(num_classes)]\n",
    "        chosen_class = np.argmax(class_sums)\n",
    "        candidate_probs = [group_pred[k][chosen_class] for k in range(len(group_pred))]\n",
    "        best_instance = np.argmax(candidate_probs)\n",
    "        y_pred.append(group_pred[best_instance])\n",
    "    \n",
    "    y_test_agg = [y_test_binary[i*group_size] for i in range(num_groups)]\n",
    "    auc_score = roc_auc_score(y_test_agg, np.array(y_pred)[:, 1], average='micro') # , multi_class='ovr'\n",
    "    class_report = classification_report(y_test_agg, np.argmax(y_pred, axis=-1))\n",
    "    print(f'Multiary AUC: {auc_score:.4f}')\n",
    "    print('class report')\n",
    "    print(class_report)\n",
    "    print('==========================')\n",
    "    \n",
    "    y_pred_tmp = y_pred\n",
    "    y_test_answer = np.zeros((len(y_test) // 27, 4))\n",
    "    # ===================================================================================\n",
    "    y_pred = y_pred_tmp # 恢復\n",
    "    X_train_tmp = X_train[np.logical_or(y_train == 0, y_train == 2)]\n",
    "    y_train_tmp = y_train[np.logical_or(y_train == 0, y_train == 2)]\n",
    "    y_idx = np.repeat(np.arange(len(y_train) // 27), 27)[np.logical_or(y_train == 0, y_train == 2)]\n",
    "    y_train_binary = y_train_tmp == 2\n",
    "    clf = SVC(C=1, random_state=42, probability=True, class_weight='balanced', kernel='linear')\n",
    "    rfe = RFE(clf, n_features_to_select=3)\n",
    "    rfe.fit(X_train_tmp, y_train_binary)\n",
    "    X_train_tmp = rfe.transform(X_train_tmp)\n",
    "        \n",
    "    clf.fit(X_train_tmp, y_train_binary)\n",
    "        \n",
    "    X_test_tmp = []\n",
    "    y_test_tmp = []\n",
    "    for i in range(0, len(y_pred)):\n",
    "        if y_pred[i][1] >= y_pred[i][0]: # 預測為 1 時\n",
    "            X_test_tmp.extend(X_test[i * 27 : (i + 1) * 27])\n",
    "            y_test_tmp.extend(y_test[i * 27 : (i + 1) * 27])\n",
    "    X_test_tmp = np.array(X_test_tmp); y_test_tmp = np.array(y_test_tmp)\n",
    "    y_test_binary = y_test_tmp == 2\n",
    "    X_test_tmp = rfe.transform(X_test_tmp)\n",
    "        \n",
    "    predicted = clf.predict_proba(X_test_tmp)\n",
    "    num_groups = len(predicted) // group_size\n",
    "    y_pred = []\n",
    "    for i in range(num_groups):\n",
    "        # 為了移除Outlier\n",
    "        group_pred = np.array(predicted[i*group_size: (i+1)*group_size])\n",
    "        num_classes = len(np.unique(y_train_binary))\n",
    "        group_label = np.argmax(group_pred, axis=1) # 算出每筆最大類\n",
    "        label = np.bincount(group_label).argmax() # 算出最多投票\n",
    "        pos_mask = group_label == label\n",
    "        group_pred = group_pred[pos_mask, :].tolist()\n",
    "        # 對每個類別計算該組內的總機率\n",
    "        class_sums = [sum([group_pred[k][j] for k in range(len(group_pred))]) for j in range(num_classes)]\n",
    "        chosen_class = np.argmax(class_sums)\n",
    "        candidate_probs = [group_pred[k][chosen_class] for k in range(len(group_pred))]\n",
    "        best_instance = np.argmax(candidate_probs)\n",
    "        y_pred.append(group_pred[best_instance])\n",
    "        \n",
    "    y_test_agg = [y_test_binary[i*group_size] for i in range(num_groups)]\n",
    "    auc_score = roc_auc_score(y_test_agg, np.array(y_pred)[:, 1], average='micro') # , multi_class='ovr'\n",
    "    class_report = classification_report(y_test_agg, np.argmax(y_pred, axis=-1))\n",
    "    print(f'Multiary AUC: {auc_score:.4f}')\n",
    "    print('class report')\n",
    "    print(class_report)\n",
    "    print('==========================')\n",
    "    \n",
    "    for j, num in zip(y_idx, y_pred):\n",
    "        y_test_answer[j][0] = num[0]\n",
    "        y_test_answer[j][2] = num[1]\n",
    "    # ===================================================================================\n",
    "    y_pred = y_pred_tmp\n",
    "    X_train_tmp = X_train[np.logical_or(y_train == 1, y_train == 3)]\n",
    "    y_train_tmp = y_train[np.logical_or(y_train == 1, y_train == 3)]\n",
    "    y_idx = np.repeat(np.arange(len(y_train) // 27), 27)[np.logical_or(y_train == 1, y_train == 3)]\n",
    "    y_train_binary = y_train_tmp == 3\n",
    "    clf = SVC(C=1, random_state=42, probability=True, class_weight='balanced', kernel='linear') # 0.7405\n",
    "    rfe = RFE(clf, n_features_to_select=16)\n",
    "    rfe.fit(X_train_tmp, y_train_binary)\n",
    "    X_train_tmp = rfe.transform(X_train_tmp)\n",
    "            \n",
    "    clf.fit(X_train_tmp, y_train_binary)\n",
    "            \n",
    "    X_test_tmp = []\n",
    "    y_test_tmp = []\n",
    "    for i in range(0, len(y_pred)):\n",
    "        if y_pred[i][1] < y_pred[i][0]: # 預測為 0 時\n",
    "            X_test_tmp.extend(X_test[i * 27 : (i + 1) * 27])\n",
    "            y_test_tmp.extend(y_test[i * 27 : (i + 1) * 27])\n",
    "    X_test_tmp = np.array(X_test_tmp); y_test_tmp = np.array(y_test_tmp)\n",
    "    y_test_binary = y_test_tmp == 3\n",
    "    X_test_tmp = rfe.transform(X_test_tmp)\n",
    "            \n",
    "    predicted = clf.predict_proba(X_test_tmp)\n",
    "    num_groups = len(predicted) // group_size\n",
    "    y_pred = []\n",
    "    for i in range(num_groups):\n",
    "        # 為了移除Outlier\n",
    "        group_pred = np.array(predicted[i*group_size: (i+1)*group_size])\n",
    "        num_classes = len(np.unique(y_train_binary))\n",
    "        group_label = np.argmax(group_pred, axis=1) # 算出每筆最大類\n",
    "        label = np.bincount(group_label).argmax() # 算出最多投票\n",
    "        pos_mask = group_label == label\n",
    "        group_pred = group_pred[pos_mask, :].tolist()\n",
    "        # 對每個類別計算該組內的總機率\n",
    "        class_sums = [sum([group_pred[k][j] for k in range(len(group_pred))]) for j in range(num_classes)]\n",
    "        chosen_class = np.argmax(class_sums)\n",
    "        candidate_probs = [group_pred[k][chosen_class] for k in range(len(group_pred))]\n",
    "        best_instance = np.argmax(candidate_probs)\n",
    "        y_pred.append(group_pred[best_instance])\n",
    "            \n",
    "    y_test_agg = [y_test_binary[i*group_size] for i in range(num_groups)]\n",
    "    auc_score = roc_auc_score(y_test_agg, np.array(y_pred)[:, 1], average='micro') # , multi_class='ovr'\n",
    "    class_report = classification_report(y_test_agg, np.argmax(y_pred, axis=-1))\n",
    "    print(f'Multiary AUC: {auc_score:.4f}')\n",
    "    print('class report')\n",
    "    print(class_report)\n",
    "    print('==========================')\n",
    "    \n",
    "    for j, num in zip(y_idx, y_pred):\n",
    "        y_test_answer[j][1] = num[0]\n",
    "        y_test_answer[j][3] = num[1]\n",
    "        \n",
    "    # ==================================\n",
    "    num_groups = len(y_test) // group_size\n",
    "    y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "    y_test_answer_norm = y_test_answer / np.sum(y_test_answer, axis=1, keepdims=True)\n",
    "    auc_score = roc_auc_score(y_test_agg, y_test_answer_norm, average='micro', multi_class='ovr') # , multi_class='ovr'\n",
    "    class_report = classification_report(y_test_agg, np.argmax(y_test_answer, axis=-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce442c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 若尚未產生特徵，請先執行 data_generate() 生成特徵 CSV 檔案\n",
    "    # data_generate()\n",
    "    \n",
    "    # 讀取訓練資訊，根據 player_id 將資料分成 80% 訓練、20% 測試\n",
    "    info = pd.read_csv('train_info.csv')\n",
    "    unique_players = info['player_id'].unique()\n",
    "    train_players, test_players = train_test_split(unique_players, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 讀取特徵 CSV 檔（位於 \"./tabular_data_train\"）\n",
    "    datapath = './tabular_data_train'\n",
    "    datalist = list(Path(datapath).glob('**/*.csv'))\n",
    "    target_mask = ['gender', 'hold racket handed', 'play years', 'level']\n",
    "    \n",
    "    # 根據 test_players 分組資料\n",
    "    X_train = pd.DataFrame()\n",
    "    y_train = pd.DataFrame(columns=target_mask)\n",
    "    X_test = pd.DataFrame()\n",
    "    y_test = pd.DataFrame(columns=target_mask)\n",
    "    \n",
    "    for file in datalist:\n",
    "        unique_id = int(Path(file).stem)\n",
    "        row = info[info['unique_id'] == unique_id]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        player_id = row['player_id'].iloc[0]\n",
    "        data = pd.read_csv(file)\n",
    "        # 後來有把mode加入考慮\n",
    "        # label = 0 代表 mode 為 1 - 8\n",
    "        # label = 1 代表 mode 為 9 - 10\n",
    "        mode = info.loc[info['unique_id'] == unique_id, 'mode'].values[0] # a scalar\n",
    "        mode_onehot = np.zeros((1))\n",
    "        mode_onehot[0] = 1 if mode >= 9 else 0\n",
    "        mode_onehot = pd.DataFrame([mode_onehot] * len(data))\n",
    "\n",
    "        target = row[target_mask]\n",
    "        target_repeated = pd.concat([target] * len(data))\n",
    "        data = pd.concat([data, mode_onehot], axis=1)\n",
    "        if player_id in train_players:\n",
    "            X_train = pd.concat([X_train, data], ignore_index=True)\n",
    "            y_train = pd.concat([y_train, target_repeated], ignore_index=True)\n",
    "        elif player_id in test_players:\n",
    "            X_test = pd.concat([X_test, data], ignore_index=True)\n",
    "            y_test = pd.concat([y_test, target_repeated], ignore_index=True)\n",
    "    print('train shape', X_train.shape)\n",
    "    print('test shape', X_test.shape)\n",
    "    X_train.columns = X_train.columns.astype(str)\n",
    "    X_test.columns = X_test.columns.astype(str)\n",
    "\n",
    "    # 標準化特徵\n",
    "    le = LabelEncoder()\n",
    "    def normalize(name, bound=10, mode=0):\n",
    "        # 這邊的bound是搭配mode\n",
    "        # 當 mode == 1 時，會選取前bound筆正相關資料\n",
    "        # 當 mode == 2 時，會移除前bound筆負相關資料\n",
    "        # mode == 0 時不改變(後來都設成mode = 0了)\n",
    "        X_corr = X_train.apply(lambda col: col.corr(y_train[name]))\n",
    "        X_corr = X_corr.sort_values(ascending=False)\n",
    "        \n",
    "        if mode == 1: # pos\n",
    "            columns = X_corr.head(bound).index.tolist()\n",
    "        elif mode == 2: # neg\n",
    "            columns = X_corr.tail(bound).index.tolist()\n",
    "        \n",
    "        if mode == 0:\n",
    "            X_train_func = X_train\n",
    "            X_test_func = X_test\n",
    "        elif mode == 1:\n",
    "            X_train_func = X_train[columns]\n",
    "            X_test_func = X_test[columns]\n",
    "        elif mode == 2:\n",
    "            X_train_func = X_train.drop(columns=columns)\n",
    "            X_test_func = X_test.drop(columns=columns)\n",
    "            \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_func)\n",
    "        X_test_scaled = scaler.transform(X_test_func)\n",
    "        return X_train_scaled, X_test_scaled\n",
    "    # =====================================================================================\n",
    "    # 評分：針對各目標進行模型訓練與評分\n",
    "    \n",
    "    # gender、hand、play year 沒有訓練，專心提升 level 的準確度\n",
    "    # 所以沒有程式碼\n",
    "    \n",
    "    X_train_scaled, X_test_scaled = normalize('level', 10, mode=0)\n",
    "    y_train_le_level = le.fit_transform(y_train['level'])\n",
    "    y_test_le_level = le.transform(y_test['level'])\n",
    "    # 進行 Oversampling\n",
    "    target_class = np.bincount(y_train_le_level).max() # label = 3 的數量(最多)\n",
    "    print('target class num', target_class)\n",
    "    # 想法 \n",
    "    # 使label = 1 or 2 能夠與 label = 3 數量相當\n",
    "    # label = 0 數量夠多了，所以不用 Oversampling\n",
    "    weights = {i : target_class for i in range(1, 3)}\n",
    "    print('weights', weights)\n",
    "    strategy = SMOTE(sampling_strategy=weights, random_state=42)\n",
    "    X_train_scaled, y_train_le_level = strategy.fit_resample(X_train_scaled, y_train_le_level)\n",
    "    # 預測\n",
    "    model_multiary(X_train_scaled, y_train_le_level, X_test_scaled, y_test_le_level, group_size=27, n_estimators=100)\n",
    "\n",
    "    #AUC SCORE: 0.792(gender) + 0.998(hold) + 0.660(years) + 0.822(levels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01e12f",
   "metadata": {},
   "source": [
    " - Test 好像有缺失值\n",
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6642065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_generate('./train_data', 'tabular_data_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7706e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (42039, 35)\n",
      "test shape (10746, 35)\n",
      "target class num 19656\n",
      "weights {1: 19656, 2: 19656}\n",
      "Multiary AUC: 0.9970\n",
      "class report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       261\n",
      "           1       0.99      1.00      1.00       137\n",
      "\n",
      "    accuracy                           1.00       398\n",
      "   macro avg       1.00      1.00      1.00       398\n",
      "weighted avg       1.00      1.00      1.00       398\n",
      "\n",
      "==========================\n",
      "Multiary AUC: 0.7827\n",
      "class report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.91      0.83       102\n",
      "        True       0.47      0.22      0.30        36\n",
      "\n",
      "    accuracy                           0.73       138\n",
      "   macro avg       0.62      0.57      0.57       138\n",
      "weighted avg       0.69      0.73      0.70       138\n",
      "\n",
      "==========================\n",
      "Multiary AUC: 0.8438\n",
      "class report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.81      0.69        86\n",
      "        True       0.89      0.74      0.81       174\n",
      "\n",
      "    accuracy                           0.76       260\n",
      "   macro avg       0.75      0.77      0.75       260\n",
      "weighted avg       0.79      0.76      0.77       260\n",
      "\n",
      "==========================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 99\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m X_train_scaled, y_train_le_level \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mfit_resample(X_train_scaled, y_train_le_level)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# 預測\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[43mmodel_multiary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_le_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_le_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m27\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 146\u001b[0m, in \u001b[0;36mmodel_multiary\u001b[1;34m(X_train, y_train, X_test, y_test, group_size, n_estimators, classifier)\u001b[0m\n\u001b[0;32m    144\u001b[0m num_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_test) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m group_size\n\u001b[0;32m    145\u001b[0m y_test_agg \u001b[38;5;241m=\u001b[39m [y_test[i\u001b[38;5;241m*\u001b[39mgroup_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_groups)]\n\u001b[1;32m--> 146\u001b[0m auc_score \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_agg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmicro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# , multi_class='ovr'\u001b[39;00m\n\u001b[0;32m    147\u001b[0m class_report \u001b[38;5;241m=\u001b[39m classification_report(y_test_agg, np\u001b[38;5;241m.\u001b[39margmax(y_test_answer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:634\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:707\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# validation of the input y_score\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[38;5;241m1\u001b[39m, y_score\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m--> 707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget scores need to be probabilities for multiclass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc, i.e. they should sum up to 1.0 over classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    710\u001b[0m     )\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# validation for multiclass parameter specifications\u001b[39;00m\n\u001b[0;32m    713\u001b[0m average_options \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e99f1",
   "metadata": {},
   "source": [
    "## Predict Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submit():   \n",
    "    train_target_mask = ['gender', 'hold racket handed', 'play years', 'level']\n",
    "    test_target_mask = ['gender', 'hold racket handed']\n",
    "    \n",
    "    # Train Data\n",
    "    train_datapath = './tabular_data_train'\n",
    "    train_datalist = list(Path(train_datapath).glob('**/*.csv'))\n",
    "    \n",
    "    train_info = pd.read_csv('train_info.csv')\n",
    "    train_players = train_info['player_id'].unique()\n",
    "    \n",
    "    # Test Data\n",
    "    test_datapath = './tabular_data_test'\n",
    "    test_datalist = list(Path(test_datapath).glob('**/*.csv'))\n",
    "    \n",
    "    test_info = pd.read_csv('test_info.csv')\n",
    "    test_players = test_info['unique_id']\n",
    "    \n",
    "    # 根據 test_players 分組資料\n",
    "    X_train = pd.DataFrame()\n",
    "    y_train = pd.DataFrame(columns=train_target_mask)\n",
    "    X_test = pd.DataFrame()\n",
    "    y_test = pd.DataFrame(columns=['unique_id'] + test_target_mask)\n",
    "    y_test['unique_id'] = test_players\n",
    "    \n",
    "    # Make Train DF\n",
    "    for file in train_datalist:\n",
    "        unique_id = int(Path(file).stem)\n",
    "        row = train_info[train_info['unique_id'] == unique_id]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        # player_id = row['player_id'].iloc[0]\n",
    "        data = pd.read_csv(file)\n",
    "        \n",
    "        mode = train_info.loc[train_info['unique_id'] == unique_id, 'mode'].values[0] # a scalar\n",
    "        mode_onehot = np.zeros((1))\n",
    "        mode_onehot[0] = 1 if mode >= 9 else 0\n",
    "        mode_onehot = pd.DataFrame([mode_onehot] * len(data))\n",
    "        \n",
    "        target = row[train_target_mask]\n",
    "        target_repeated = pd.concat([target] * len(data))\n",
    "        data = pd.concat([data, mode_onehot], axis=1)\n",
    "        X_train = pd.concat([X_train, data], ignore_index=True)\n",
    "        y_train = pd.concat([y_train, target_repeated], ignore_index=True)\n",
    "\n",
    "    # Make Test DF\n",
    "    for file in test_datalist:\n",
    "        unique_id = int(Path(file).stem)\n",
    "        row = test_info[test_info['unique_id'] == unique_id]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        # player_id = row['player_id'].iloc[0]\n",
    "        data = pd.read_csv(file)\n",
    "        if data.empty:\n",
    "            print(file)\n",
    "            \n",
    "        mode = test_info.loc[test_info['unique_id'] == unique_id, 'mode'].values[0] # a scalar\n",
    "        mode_onehot = np.zeros((1))\n",
    "        mode_onehot[0] = 1 if mode >= 9 else 0\n",
    "        mode_onehot = pd.DataFrame([mode_onehot] * len(data))\n",
    "        \n",
    "        # target = row[target_mask]\n",
    "        # target_repeated = pd.concat([target] * len(data))\n",
    "        data = pd.concat([data, mode_onehot], axis=1)\n",
    "        X_test = pd.concat([X_test, data], ignore_index=True)\n",
    "        # y_test = pd.concat([y_test, target_repeated], ignore_index=True)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    X_train.columns = X_train.columns.astype(str)\n",
    "    X_test.columns = X_test.columns.astype(str)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    def normalize(name, bound=10, mode=0):\n",
    "        X_corr = X_train.apply(lambda col: col.corr(y_train[name]))\n",
    "        X_corr = X_corr.sort_values(ascending=False)\n",
    "        \n",
    "        if mode == 1: # pos\n",
    "            columns = X_corr.head(bound).index.tolist()\n",
    "        elif mode == 2: # neg\n",
    "            columns = X_corr.tail(bound).index.tolist()\n",
    "        \n",
    "        if mode == 0:\n",
    "            X_train_func = X_train\n",
    "            X_test_func = X_test\n",
    "        elif mode == 1:\n",
    "            X_train_func = X_train[columns]\n",
    "            X_test_func = X_test[columns]\n",
    "        elif mode == 2:\n",
    "            X_train_func = X_train.drop(columns=columns)\n",
    "            X_test_func = X_test.drop(columns=columns)\n",
    "            \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_func)\n",
    "        X_test_scaled = scaler.transform(X_test_func)\n",
    "        return X_train_scaled, X_test_scaled\n",
    "    # =====================================================================================\n",
    "    def model_binary_pred(X_train, y_train, X_test, y_test, name, group_size=27, n_estimators=100):\n",
    "        # clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42, class_weight='balanced')\n",
    "        clf = GradientBoostingClassifier(n_estimators=n_estimators, random_state=42)\n",
    "        num_class = [(y_train == 0).sum(), (y_train == 1).sum()]\n",
    "        num_class = {i: len(y_train) / num for i, num in enumerate(num_class)}\n",
    "        sample_weight = np.zeros(len(y_train))\n",
    "        for i in range(2):\n",
    "            sample_weight[np.where(y_train == i)] = num_class[i]\n",
    "        \n",
    "        clf.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        \n",
    "        predicted = clf.predict_proba(X_test)\n",
    "        # 取出正類（index 1）的概率\n",
    "        predicted = [1 - predicted[i][1] for i in range(len(predicted))]\n",
    "\n",
    "        y_pred = []\n",
    "        num_groups = len(predicted) // group_size \n",
    "        for i in range(num_groups):\n",
    "            now_group = np.array(predicted[i*group_size: (i+1)*group_size])\n",
    "            pred_label = 0 if (now_group <= 0.5).sum() > (now_group > 0.5).sum() else 1 # 決定他是0還是1\n",
    "            if pred_label == 0: \n",
    "                pos_mask = now_group <= 0.5\n",
    "                y_pred.append(now_group[pos_mask].min())\n",
    "            else: \n",
    "                pos_mask = now_group > 0.5\n",
    "                y_pred.append(now_group[pos_mask].max())  \n",
    "            \n",
    "        # y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "        y_test[name] = y_pred\n",
    "        \n",
    "    # 定義多類別分類評分函數 (例如 play years、level)\n",
    "    def model_multiary_pred(X_train, y_train, X_test, y_test, name:list, group_size=27, n_estimators=100, classifier=None):\n",
    "        y_train_binary = np.logical_or(y_train == 0, y_train == 2)\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, random_state=42, class_weight='balanced', \n",
    "                                        criterion='entropy', oob_score=True)\n",
    "        clf.fit(X_train, y_train_binary)\n",
    "        \n",
    "        # y_test_binary = np.logical_or(y_test == 0, y_test == 2).astype(int)\n",
    "        \n",
    "        predicted = clf.predict_proba(X_test)\n",
    "        num_groups = len(predicted) // group_size\n",
    "        y_pred = []\n",
    "        for i in range(num_groups):\n",
    "            # 為了移除Outlier\n",
    "            group_pred = np.array(predicted[i*group_size: (i+1)*group_size])\n",
    "            num_classes = len(np.unique(y_train_binary))\n",
    "            group_label = np.argmax(group_pred, axis=1) # 算出每筆最大類\n",
    "            label = np.bincount(group_label).argmax() # 算出最多投票\n",
    "            pos_mask = group_label == label\n",
    "            group_pred = group_pred[pos_mask, :].tolist()\n",
    "            # 對每個類別計算該組內的總機率\n",
    "            class_sums = [sum([group_pred[k][j] for k in range(len(group_pred))]) for j in range(num_classes)]\n",
    "            chosen_class = np.argmax(class_sums)\n",
    "            candidate_probs = [group_pred[k][chosen_class] for k in range(len(group_pred))]\n",
    "            best_instance = np.argmax(candidate_probs)\n",
    "            y_pred.append(group_pred[best_instance])\n",
    "        \n",
    "        # y_test_agg = [y_test_binary[i*group_size] for i in range(num_groups)]\n",
    "        # auc_score = roc_auc_score(y_test_agg, np.array(y_pred)[:, 1], average='micro') # , multi_class='ovr'\n",
    "        # class_report = classification_report(y_test_agg, np.argmax(y_pred, axis=-1))\n",
    "        # print(f'Multiary AUC: {auc_score:.4f}')\n",
    "        # print('class report')\n",
    "        # print(class_report)\n",
    "        # print('==========================')\n",
    "        \n",
    "        y_pred_tmp = y_pred\n",
    "        y_test_answer = np.zeros((len(X_test) // 27, 4))\n",
    "        # ===================================================================================\n",
    "        print('predict 0 2')\n",
    "        y_pred = y_pred_tmp # 恢復\n",
    "        X_train_tmp = X_train[np.logical_or(y_train == 0, y_train == 2)]\n",
    "        y_train_tmp = y_train[np.logical_or(y_train == 0, y_train == 2)]\n",
    "        y_idx = np.repeat(np.arange(len(y_train) // 27), 27)[np.logical_or(y_train == 0, y_train == 2)]\n",
    "        y_train_binary = y_train_tmp == 2\n",
    "        clf = SVC(C=1, random_state=42, probability=True, class_weight='balanced', kernel='linear')\n",
    "        rfe = RFE(clf, n_features_to_select=3)\n",
    "        rfe.fit(X_train_tmp, y_train_binary)\n",
    "        X_train_tmp = rfe.transform(X_train_tmp)\n",
    "            \n",
    "        clf.fit(X_train_tmp, y_train_binary)\n",
    "            \n",
    "        X_test_tmp = []\n",
    "        # y_test_tmp = []\n",
    "        for i in range(0, len(y_pred)):\n",
    "            if y_pred[i][1] >= y_pred[i][0]: # 預測為 1 時\n",
    "                X_test_tmp.extend(X_test[i * 27 : (i + 1) * 27])\n",
    "                # y_test_tmp.extend(y_test[i * 27 : (i + 1) * 27])\n",
    "        X_test_tmp = np.array(X_test_tmp); \n",
    "        # y_test_tmp = np.array(y_test_tmp)\n",
    "        # y_test_binary = y_test_tmp == 2\n",
    "        X_test_tmp = rfe.transform(X_test_tmp)\n",
    "            \n",
    "        predicted = clf.predict_proba(X_test_tmp)\n",
    "        num_groups = len(predicted) // group_size\n",
    "        y_pred = []\n",
    "        for i in range(num_groups):\n",
    "            # 為了移除Outlier\n",
    "            group_pred = np.array(predicted[i*group_size: (i+1)*group_size])\n",
    "            num_classes = len(np.unique(y_train_binary))\n",
    "            group_label = np.argmax(group_pred, axis=1) # 算出每筆最大類\n",
    "            label = np.bincount(group_label).argmax() # 算出最多投票\n",
    "            pos_mask = group_label == label\n",
    "            group_pred = group_pred[pos_mask, :].tolist()\n",
    "            # 對每個類別計算該組內的總機率\n",
    "            class_sums = [sum([group_pred[k][j] for k in range(len(group_pred))]) for j in range(num_classes)]\n",
    "            chosen_class = np.argmax(class_sums)\n",
    "            candidate_probs = [group_pred[k][chosen_class] for k in range(len(group_pred))]\n",
    "            best_instance = np.argmax(candidate_probs)\n",
    "            y_pred.append(group_pred[best_instance])\n",
    "            \n",
    "        # y_test_agg = [y_test_binary[i*group_size] for i in range(num_groups)]\n",
    "        # auc_score = roc_auc_score(y_test_agg, np.array(y_pred)[:, 1], average='micro') # , multi_class='ovr'\n",
    "        # class_report = classification_report(y_test_agg, np.argmax(y_pred, axis=-1))\n",
    "        # print(f'Multiary AUC: {auc_score:.4f}')\n",
    "        # print('class report')\n",
    "        # print(class_report)\n",
    "        # print('==========================')\n",
    "        \n",
    "        for j, num in zip(y_idx, y_pred):\n",
    "            y_test_answer[j][0] = num[0]\n",
    "            y_test_answer[j][2] = num[1]\n",
    "        # ===================================================================================\n",
    "        print('predict 1 3')\n",
    "        y_pred = y_pred_tmp\n",
    "        X_train_tmp = X_train[np.logical_or(y_train == 1, y_train == 3)]\n",
    "        y_train_tmp = y_train[np.logical_or(y_train == 1, y_train == 3)]\n",
    "        y_idx = np.repeat(np.arange(len(y_train) // 27), 27)[np.logical_or(y_train == 1, y_train == 3)]\n",
    "        y_train_binary = y_train_tmp == 3\n",
    "        clf = SVC(C=1, random_state=42, probability=True, class_weight='balanced', kernel='linear') # 0.7405\n",
    "        rfe = RFE(clf, n_features_to_select=16)\n",
    "        rfe.fit(X_train_tmp, y_train_binary)\n",
    "        X_train_tmp = rfe.transform(X_train_tmp)\n",
    "                \n",
    "        clf.fit(X_train_tmp, y_train_binary)\n",
    "                \n",
    "        X_test_tmp = []\n",
    "        # y_test_tmp = []\n",
    "        for i in range(0, len(y_pred)):\n",
    "            if y_pred[i][1] < y_pred[i][0]: # 預測為 0 時\n",
    "                X_test_tmp.extend(X_test[i * 27 : (i + 1) * 27])\n",
    "                # y_test_tmp.extend(y_test[i * 27 : (i + 1) * 27])\n",
    "        X_test_tmp = np.array(X_test_tmp); \n",
    "        # y_test_tmp = np.array(y_test_tmp)\n",
    "        # y_test_binary = y_test_tmp == 3\n",
    "        X_test_tmp = rfe.transform(X_test_tmp)\n",
    "                \n",
    "        predicted = clf.predict_proba(X_test_tmp)\n",
    "        num_groups = len(predicted) // group_size\n",
    "        y_pred = []\n",
    "        for i in range(num_groups):\n",
    "            # 為了移除Outlier\n",
    "            group_pred = np.array(predicted[i*group_size: (i+1)*group_size])\n",
    "            num_classes = len(np.unique(y_train_binary))\n",
    "            group_label = np.argmax(group_pred, axis=1) # 算出每筆最大類\n",
    "            label = np.bincount(group_label).argmax() # 算出最多投票\n",
    "            pos_mask = group_label == label\n",
    "            group_pred = group_pred[pos_mask, :].tolist()\n",
    "            # 對每個類別計算該組內的總機率\n",
    "            class_sums = [sum([group_pred[k][j] for k in range(len(group_pred))]) for j in range(num_classes)]\n",
    "            chosen_class = np.argmax(class_sums)\n",
    "            candidate_probs = [group_pred[k][chosen_class] for k in range(len(group_pred))]\n",
    "            best_instance = np.argmax(candidate_probs)\n",
    "            y_pred.append(group_pred[best_instance])\n",
    "                \n",
    "        # y_test_agg = [y_test_binary[i*group_size] for i in range(num_groups)]\n",
    "        # auc_score = roc_auc_score(y_test_agg, np.array(y_pred)[:, 1], average='micro') # , multi_class='ovr'\n",
    "        # class_report = classification_report(y_test_agg, np.argmax(y_pred, axis=-1))\n",
    "        # print(f'Multiary AUC: {auc_score:.4f}')\n",
    "        # print('class report')\n",
    "        # print(class_report)\n",
    "        # print('==========================')\n",
    "        \n",
    "        for j, num in zip(y_idx, y_pred):\n",
    "            y_test_answer[j][1] = num[0]\n",
    "            y_test_answer[j][3] = num[1]\n",
    "            \n",
    "        # ==================================\n",
    "        # num_groups = len(y_test) // group_size\n",
    "        # y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "        # auc_score = roc_auc_score(y_test_agg, y_test_answer, average='micro', multi_class='ovr') # , multi_class='ovr'\n",
    "        # class_report = classification_report(y_test_agg, np.argmax(y_test_answer, axis=-1))\n",
    "        \n",
    "        # print(y_pred.shape)\n",
    "        for i, n in enumerate(name):\n",
    "            y_test[n] = y_test_answer[:, i]\n",
    "        \n",
    "        # y_test_agg = [y_test[i*group_size] for i in range(num_groups)]\n",
    "        # auc_score = roc_auc_score(y_test_agg, y_pred, average='micro', multi_class='ovr')\n",
    "        # print('Multiary AUC:', auc_score)\n",
    "        \n",
    "    # =====================================================================================\n",
    "    # 評分：針對各目標進行模型訓練與評分\n",
    "    print('Start Prediction')\n",
    "    X_train_scaled, X_test_scaled = normalize('gender', 10, 2)\n",
    "    y_train_le_gender = le.fit_transform(y_train['gender'])\n",
    "    # model_binary_pred(X_train_scaled, y_train_le_gender, X_test_scaled, y_test, 'gender', group_size=27)\n",
    "    \n",
    "    X_train_scaled, X_test_scaled = normalize('hold racket handed', mode=0)\n",
    "    y_train_le_hold = le.fit_transform(y_train['hold racket handed'])\n",
    "    # model_binary_pred(X_train_scaled, y_train_le_hold, X_test_scaled, y_test, 'hold racket handed', group_size=27)\n",
    "    \n",
    "    X_train_scaled, X_test_scaled = normalize('play years', 10, mode=0)\n",
    "    y_train_le_years = le.fit_transform(y_train['play years'])\n",
    "    labels = ['play years_0', 'play years_1', 'play years_2']\n",
    "    # model_multiary_pred(X_train_scaled, y_train_le_years, X_test_scaled, y_test, labels, group_size=27, classifier='')\n",
    "    \n",
    "    X_train_scaled, X_test_scaled = normalize('level', 10, mode=0)\n",
    "    y_train_le_level = le.fit_transform(y_train['level'])\n",
    "    labels = ['level_2', 'level_3', 'level_4', 'level_5']\n",
    "    target_class = np.bincount(y_train_le_level).max()\n",
    "    print('target class num', target_class)\n",
    "    weights = {i : target_class for i in range(1, 3)}\n",
    "    print('weights', weights)\n",
    "    strategy = SMOTE(sampling_strategy=weights)\n",
    "    X_train_scaled, y_train_le_level = strategy.fit_resample(X_train_scaled, y_train_le_level)\n",
    "    model_multiary_pred(X_train_scaled, y_train_le_level, X_test_scaled, y_test, labels, group_size=27, n_estimators=100)\n",
    "    \n",
    "    y_test.to_csv('submit.csv', index=False)\n",
    "    print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad78a8f",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633b7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52785, 35)\n",
      "(38610, 35)\n",
      "Start Prediction\n",
      "target class num 24381\n",
      "weights {1: 24381, 2: 24381}\n",
      "predict 0 2\n",
      "predict 1 3\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "make_submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
